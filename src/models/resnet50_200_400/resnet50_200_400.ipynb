{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80000 files belonging to 200 classes.\n",
      "Using 64000 files for training.\n",
      "Found 80000 files belonging to 200 classes.\n",
      "Using 16000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train = image_dataset_from_directory('../data/french_bird_db_200_400', labels='inferred', image_size=(300, 300), validation_split=0.2, subset=\"training\",\n",
    "seed=42, batch_size=320)\n",
    "\n",
    "ds_test = image_dataset_from_directory('../data/french_bird_db_200_400', labels='inferred', image_size=(300, 300), validation_split=0.2, subset=\"validation\",\n",
    "seed=42, batch_size=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ds_train.class_names\n",
    "num_classes = len(ds_train.class_names)\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
    "\n",
    "ds_train_preprocessed = ds_train.map(lambda x, y: (preprocess_input(x), y))\n",
    "ds_test_preprocessed = ds_test.map(lambda x, y: (preprocess_input(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 16:05:47.897191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  9/200\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:11\u001b[0m 9s/step - loss: 13.1793 - sparse_categorical_accuracy: 0.0081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle sur votre dataset avec le callback personnalisé\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_train_preprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_test_preprocessed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()\n",
    "\n",
    "# Charger le modèle ResNet50 pré-entraîné avec les poids ImageNet\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Ajouter une couche de pooling global pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x_2 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x_3 = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x_2)\n",
    "x_3 = Dropout(0.5)(x_3)\n",
    "\n",
    "\n",
    "# Ajouter une couche dense pour effectuer la classification\n",
    "output = Dense(num_classes, activation='softmax')(x_3)\n",
    "\n",
    "# Créer le modèle final en combinant le modèle de base et les couches supplémentaires\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Geler les couches du modèle de base pour éviter de les entraîner\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "\n",
    "# Entraîner le modèle sur votre dataset avec le callback personnalisé\n",
    "history = model.fit(ds_train_preprocessed, epochs=5, batch_size=320, callbacks=callbacks, validation_data=ds_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_model.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_weights('current_model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "42 spatula_querquedula\n"
     ]
    }
   ],
   "source": [
    "image_test = keras.utils.load_img(\n",
    "    '../data/french_bird_db_50_100/apus_apus/apus_apus_10.jpg',\n",
    ")\n",
    "\n",
    "image_array = keras.utils.img_to_array(image_test)\n",
    "\n",
    "image_processed = preprocess_input(image_array)\n",
    "# ds_train_preprocessed = ds_train.map(lambda x, y: (preprocess_input(x), y))\n",
    "print(image_processed.shape)\n",
    "\n",
    "test = np.argmax(model.predict(np.expand_dims(image_processed, axis=0)))\n",
    "\n",
    "print(test, class_names[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step\n",
      "[29 31  6 38 23 35 10 36  0 20 35 17  7 22 32 36  4  5  4 46 29 39 37  1\n",
      "  1  3 37 37 47 45 39 21 39 32 11  4 20 41 28 15 18 13 36 42  4 30 15 42\n",
      " 14 41 49 28 18 30 31 46 29 40  1 26 26 42 26 34]\n",
      "tf.Tensor(\n",
      "[29 31  6 38 23 35 10 28  0  6 35 17  7 22 32 16  4  5  4 46 23 39 37 27\n",
      " 28  3 37 37 47 16 39 21 39 32 11  4 20 41 28 15 18 13 36 43  4 30 15 38\n",
      " 14 41 49 27 18 30 31 46 30 40  1 26 26 49 26 34], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in ds_train_preprocessed:\n",
    "  batch_pred = model.predict(image_batch)\n",
    "  class_pred = np.argmax(batch_pred, axis=1)\n",
    "  print(class_pred)\n",
    "  print(labels_batch)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722ms/step\n",
      "batch No 0 with result:  [92.33191  50.998886 94.86049  99.334915 47.39811  74.51995  85.06272\n",
      " 62.211735 30.249184 95.44793  27.761698 22.99988  88.10974  51.252705\n",
      " 92.94134  88.10425  42.539272 39.783073 85.60944  65.02477  31.592268\n",
      " 30.340868 36.202084 28.147339 81.10364  93.99651  73.191795 72.8503\n",
      " 89.825005 86.84129  62.19917  59.047256 97.512924 39.510487 88.72931\n",
      " 87.14251  51.50335  77.28859  55.37567  51.019787 44.48908  99.6562\n",
      " 82.17718  50.671024 90.80182  85.999466 43.20118  30.971241 98.78494\n",
      " 92.87075  78.97164  88.769615 82.06567  29.477167 40.842495 87.92472\n",
      " 76.71177  86.73783  99.663475 97.754524 91.146675 99.167564 51.230217\n",
      " 89.55529 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683ms/step\n",
      "batch No 1 with result:  [89.73922  41.327324 40.21643  79.10757  42.733063 91.43583  96.009125\n",
      " 22.446022 74.80963  79.72755  52.804817 33.536697 92.71812  71.357185\n",
      " 23.531012 68.89083  94.845024 41.654507 49.17503  98.281136 90.06487\n",
      " 55.208023 22.310022 99.22099  20.959745 24.716211 16.306686 95.704384\n",
      " 37.256744 61.726677 33.436882 15.907301 45.5881   49.160107 74.27596\n",
      " 98.0338   86.97128  88.62956  53.35257  97.70865  99.25022  59.996353\n",
      " 34.561382 48.98082  30.19522  85.13657  90.79553  71.09468  86.91433\n",
      " 45.11214  75.25495  91.3088   95.26855  97.4543   35.398907 86.85729\n",
      " 61.944683 92.62347  84.39285  66.21725  89.41651  98.60408  38.20962\n",
      " 99.71853 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697ms/step\n",
      "batch No 2 with result:  [99.19141  94.70565  49.627808 28.87701  31.726425 87.44274  87.34632\n",
      " 46.175037 65.89868  89.352    85.72228  65.091446 49.335308 32.889553\n",
      " 88.988785 90.789566 87.962776 99.81835  70.5161   33.916893 81.42776\n",
      " 93.37595  49.218483 52.851475 99.35364  83.58196  53.276093 54.196938\n",
      " 99.96456  29.925009 69.47204  70.86248  24.709394 92.77586  62.486946\n",
      " 76.58778  74.63129  86.26899  98.196884 74.94168  34.016132 51.274227\n",
      " 88.67282  62.306953 48.993744 98.72049  93.673065 81.81816  62.09244\n",
      " 58.878826 79.700966 38.33466  78.86296  54.806328 73.26946  58.91118\n",
      " 22.967342 26.603964 78.83446  58.277737 75.967735 36.0421   44.677387\n",
      " 69.837036] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step\n",
      "batch No 3 with result:  [96.28101  32.47725  63.345192 99.777115 38.67893  99.944    61.756676\n",
      " 34.847702 74.12877  44.59723  58.063263 90.79003  52.54286  72.282104\n",
      " 54.589695 78.25908  37.110294 38.338844 89.92466  88.925064 92.63596\n",
      " 91.3656   25.198551 83.2113   57.715256 75.11957  85.31631  48.533215\n",
      " 79.716736 95.31337  63.187737 87.405136 93.96496  97.98071  99.98826\n",
      " 44.840824 98.343475 50.71277  19.869238 96.84346  92.202065 99.933975\n",
      " 59.143406 46.206062 65.36635  93.16275  50.930916 44.418114 94.34666\n",
      " 74.82572  82.85897  99.332825 62.908165 17.901201 47.281845 60.321323\n",
      " 97.618065 15.748638 81.77881  98.97255  31.594213 59.701736 96.92504\n",
      " 86.600006] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step\n",
      "batch No 4 with result:  [55.844677 96.99286  49.580627 33.804016 64.955124 95.735306 43.11001\n",
      " 24.428614 64.811584 30.427042 41.482334 75.12543  53.42362  30.051105\n",
      " 97.90253  88.97993  94.31917  98.631676 66.18513  74.983665 42.335632\n",
      " 15.511504 79.427704 79.0549   53.69522  62.875088 72.74692  27.811056\n",
      " 24.879519 30.271614 43.76322  75.57028  63.38323  52.213787 91.14781\n",
      " 87.61841  44.41316  49.26007  72.84403  94.626076 96.8171   82.39756\n",
      " 24.517944 81.99926  93.37546  82.593994 21.337683 51.586906 93.209114\n",
      " 40.486576 66.05346  93.59368  64.36799  80.51544  42.471184 62.63839\n",
      " 36.80339  41.33704  94.21726  76.473076 88.26733  92.79374  52.238846\n",
      " 91.60369 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n",
      "batch No 5 with result:  [51.2528   27.425858 63.34909  93.146225 70.337204 42.251183 98.942566\n",
      " 75.4147   95.2064   88.247536 29.690653 83.89628  63.14568  89.13523\n",
      " 31.657822 84.920296 60.099403 74.60856  30.873755 96.9137   55.495174\n",
      " 20.280067 44.305515 39.451714 98.412834 75.84885  62.790775 48.01045\n",
      " 97.860794 66.32286  61.41057  70.696014 52.107777 76.950905 99.46439\n",
      " 98.818214 97.50875  90.97944  32.556866 80.319756 49.626633 58.50244\n",
      " 91.842094 72.85097  42.757267 54.286938 72.38141  96.86218  42.99703\n",
      " 79.759895 39.72968  94.00792  77.9302   81.15921  26.780096 46.59713\n",
      " 31.85179  79.72106  42.82962  56.42912  22.033014 39.636845 99.988365\n",
      " 49.168854] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705ms/step\n",
      "batch No 6 with result:  [51.044613 67.107285 83.79147  61.76352  38.90328  97.71117  29.081387\n",
      " 83.616    60.93571  75.865776 91.666016 84.43333  48.436764 54.990364\n",
      " 63.35693  35.390057 97.650856 85.320076 43.203495 17.849566 82.74025\n",
      " 98.72914  34.100464 86.48292  82.93793  69.35963  83.9125   81.97897\n",
      " 66.86326  26.24155  27.682579 42.088364 77.841774 45.835022 98.29689\n",
      " 90.6833   43.97622  85.35776  84.44356  55.29353  83.8072   88.33668\n",
      " 27.126434 29.787762 24.590176 99.79933  92.44133  59.02819  83.4103\n",
      " 60.78736  48.584522 61.608772 98.4119   60.239803 91.419876 84.112495\n",
      " 98.0721   97.74129  40.486607 31.879324 55.576057 30.899637 38.887234\n",
      " 73.03359 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step\n",
      "batch No 7 with result:  [99.926636 86.21345  83.57877  98.100266 66.00966  94.853226 69.67666\n",
      " 39.698982 97.84273  64.58812  99.592575 98.63507  81.46876  90.176125\n",
      " 62.39272  89.38904  94.85279  53.80802  79.297905 65.67728  99.5753\n",
      " 97.44014  90.27771  94.86535  42.51367  63.735832 30.821636 56.704784\n",
      " 91.21572  34.886307 37.617935 98.60605  45.92359  59.22697  85.96536\n",
      " 67.21171  68.28454  76.00999  73.00295  88.501366 99.88514  88.355835\n",
      " 94.19556  85.43953  84.56096  39.198624 94.254944 92.003204 17.271427\n",
      " 18.80673  53.53719  60.530876 65.700836 38.354256 74.91127  79.07243\n",
      " 82.799164 66.08037  70.68282  57.147045 23.611597 37.725563 66.17606\n",
      " 40.903397] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701ms/step\n",
      "batch No 8 with result:  [33.862694 85.98593  45.27336  39.43012  31.83233  30.161678 46.549644\n",
      " 14.598814 64.87387  97.60725  36.474583 33.6978   35.63468  93.71375\n",
      " 91.95625  41.22728  90.361755 41.83146  95.92824  75.34884  71.30655\n",
      " 29.075834 60.543205 64.53183  68.26909  63.522003 99.86682  83.42188\n",
      " 48.106228 86.181274 40.980305 27.149105 98.756065 28.637308 98.166565\n",
      " 90.59734  67.36931  54.413498 35.280975 48.42975  95.910484 41.88475\n",
      " 79.06959  26.441414 99.08422  86.1706   30.24259  96.65278  55.493725\n",
      " 80.09109  43.054108 55.616474 87.9395   78.45608  74.88148  34.271824\n",
      " 42.85672  43.45644  96.52375  36.626255 60.996544 80.21664  25.012625\n",
      " 93.96862 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699ms/step\n",
      "batch No 9 with result:  [64.11372  98.42382  99.70981  37.192665 40.090836 97.6413   98.07659\n",
      " 84.709015 18.575676 38.69318  76.579285 68.02824  56.62933  33.54352\n",
      " 95.57213  94.83159  74.64631  84.503975 53.188145 97.12531  97.42465\n",
      " 81.86677  76.23344  83.379456 99.801865 39.027973 53.691936 96.89707\n",
      " 49.556274 27.83717  63.349384 70.58264  45.12411  84.32884  97.586426\n",
      " 50.94097  53.30258  93.85691  98.95733  91.497955 75.44025  70.36462\n",
      " 89.78024  77.597565 55.93137  29.110134 50.96221  88.03181  34.88578\n",
      " 41.934124 98.2042   43.39431  88.986115 97.07609  97.67558  25.725958\n",
      " 41.65003  94.9867   75.88533  48.70866  64.418884 79.20186  15.988445\n",
      " 53.681374] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step\n",
      "batch No 10 with result:  [91.205635 25.02121  45.80442  95.77161  49.812626 94.1677   45.63366\n",
      " 59.88136  43.7498   64.38202  34.5955   93.03086  51.870476 18.086283\n",
      " 39.35339  53.07644  82.914474 76.99258  33.380375 57.09129  80.53437\n",
      " 22.000801 40.602634 65.550865 41.76231  39.863953 85.398384 38.71864\n",
      " 24.35056  25.999954 62.528217 90.38453  83.934425 65.14624  95.20103\n",
      " 72.849724 52.846848 72.02319  44.178596 81.39519  60.631924 99.75304\n",
      " 77.87964  42.538754 31.652632 99.73377  76.03693  94.27292  93.0293\n",
      " 79.30548  56.016933 49.305824 37.950375 85.513626 70.11935  67.102806\n",
      " 17.948513 67.718636 74.009186 49.000626 21.214884 68.77767  69.47733\n",
      " 96.86076 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695ms/step\n",
      "batch No 11 with result:  [18.689589 77.55095  95.238434 51.918507 35.15658  29.882734 60.939003\n",
      " 97.602844 51.35851  38.187702 72.72947  29.630882 41.71386  99.99589\n",
      " 69.14183  69.090515 97.202774 55.254143 64.808586 67.67185  77.69177\n",
      " 36.509327 42.380234 89.0021   30.323198 41.527046 97.05384  56.0295\n",
      " 76.55669  51.949512 44.47513  98.81517  40.661358 36.12299  84.691475\n",
      " 96.120346 82.29241  96.530304 59.37413  97.85961  30.313051 44.055386\n",
      " 30.45308  57.72966  36.778088 27.61934  86.0177   98.184044 99.41446\n",
      " 29.903688 23.316607 24.896809 80.7344   77.689125 15.569584 97.423706\n",
      " 58.58325  44.512756 95.01773  98.86184  35.14637  68.89081  87.49485\n",
      " 73.28155 ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n",
      "batch No 12 with result:  [42.285168  54.751503  97.73926   51.099945  96.49493   11.247965\n",
      " 57.9289    65.46021   60.483868  65.17112   44.28871   30.133026\n",
      " 97.71649   47.875973  43.211052  81.94421   89.98121   99.185295\n",
      " 42.7717    57.281322  44.185795  33.887688  42.894096  86.132835\n",
      " 89.96511   98.32814   37.181213  68.3736    78.67685   31.214813\n",
      " 92.60289   85.95551   63.39746   27.301785  36.63259   92.742424\n",
      " 97.45107   99.74452   63.640713  85.63558   46.21551   98.028114\n",
      " 13.7573805 60.46396   61.564972  65.648544  38.924103  36.365147\n",
      " 41.849606  41.48785   89.65371   65.04649   96.59431   48.03484\n",
      " 74.45617   24.246635  95.36223   36.313663  46.565907  77.46398\n",
      " 97.14261   51.771008  29.766375  21.62972  ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n",
      "batch No 13 with result:  [50.57454  30.150917 98.83373  83.33585  14.876734 64.484535 72.081665\n",
      " 79.93787  26.066313 36.513702 70.563484 51.48841  95.20133  99.23159\n",
      " 22.876202 17.907507 84.28133  33.38574  62.29521  76.336845 83.59782\n",
      " 56.90856  46.8757   47.7799   36.702953 55.252544 46.555717 47.94341\n",
      " 91.15753  88.94984  83.1651   15.304683 99.6097   94.90503  36.12855\n",
      " 49.237576 85.647736 59.48457  27.630196 93.643745 95.93755  99.35857\n",
      " 99.71103  82.60214  76.34361  64.422134 66.67239  28.925535 36.328392\n",
      " 47.53301  79.300674 33.617233 98.07011  62.304974 96.157005 66.42636\n",
      " 44.942753 76.17718  46.54189  48.995724 92.045456 21.547676 49.300106\n",
      " 31.053015] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n",
      "batch No 14 with result:  [98.49209  41.247875 28.185623 55.561413 99.79937  30.030302 92.60439\n",
      " 57.43571  49.764973 77.57412  17.039698 34.867485 42.355244 98.068794\n",
      " 73.30443  62.836033 78.616714 42.073204 25.769783 31.919998 63.982887\n",
      " 38.193733 59.174572 93.29331  26.174397 82.91716  97.16261  86.416954\n",
      " 94.495155 50.923096 67.56743  77.78739  51.580738 99.99892  83.224236\n",
      " 69.54409  93.48459  97.35901  93.09863  31.926199 99.24309  91.013336\n",
      " 17.377071 78.67887  29.106766 52.4185   86.22313  21.018322 65.55586\n",
      " 94.88658  83.27367  33.596645 83.528175 42.47622  77.675964 86.63029\n",
      " 56.33002  53.86408  36.87824  51.35516  65.48662  36.75771  33.300243\n",
      " 41.7132  ] %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
      "batch No 15 with result:  [79.925156 61.937744 35.713543 98.029594 45.620747 76.61025  30.248293\n",
      " 51.206516 65.22678  59.186382 67.38425  62.91326  74.41184  95.80587\n",
      " 52.46712  42.63847  46.663155 75.097015 46.153706 82.3787   70.325966\n",
      " 97.64833  72.47063  33.810787 27.652212 28.581747 85.794334 99.72222\n",
      " 98.71529  15.364226 63.25158  44.518337 69.97993  94.61462  54.314907\n",
      " 27.410639 23.339935 68.86662  97.21839  41.806923] %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 15:28:24.533678: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i, (image_batch, labels_batch) in enumerate(ds_test_preprocessed):\n",
    "  batch_pred = model.predict(image_batch)\n",
    "  max = np.max(batch_pred, axis=1)\n",
    "  \n",
    "  print('batch No {} with result: '.format(i), max * 100, '%')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step\n",
      "batch No 0 with result:  84.375 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
      "batch No 1 with result:  78.125 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
      "batch No 2 with result:  70.3125 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step\n",
      "batch No 3 with result:  70.3125 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step\n",
      "batch No 4 with result:  81.25 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step\n",
      "batch No 5 with result:  79.6875 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step\n",
      "batch No 6 with result:  76.5625 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n",
      "batch No 7 with result:  75.0 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
      "batch No 8 with result:  73.4375 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step\n",
      "batch No 9 with result:  70.3125 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step\n",
      "batch No 10 with result:  78.125 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step\n",
      "batch No 11 with result:  79.6875 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step\n",
      "batch No 12 with result:  67.1875 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step\n",
      "batch No 13 with result:  71.875 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699ms/step\n",
      "batch No 14 with result:  81.25 %\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step  \n",
      "batch No 15 with result:  75.0 %\n",
      "FINAL RES =  0.7578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 14:58:08.931451: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i, (image_batch, labels_batch) in enumerate(ds_test_preprocessed):\n",
    "  batch_pred = model.predict(image_batch)\n",
    "  class_pred = np.argmax(batch_pred, axis=1)\n",
    "  res = sum((class_pred == labels_batch).numpy()) / len(class_pred)\n",
    "  total += res\n",
    "  \n",
    "  print('batch No {} with result: '.format(i), res * 100, '%')\n",
    "  \n",
    "print('FINAL RES = ', total / len(ds_test_preprocessed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
