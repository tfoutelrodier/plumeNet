{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 files belonging to 25 classes.\n",
      "Using 2000 files for training.\n",
      "Found 2500 files belonging to 25 classes.\n",
      "Using 500 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "ds_train = image_dataset_from_directory('../data/french_bird_db_25_100', labels='inferred', image_size=(300, 300), validation_split=0.2, subset=\"training\",\n",
    "seed=42, label_mode = \"int\", color_mode = \"rgb\", batch_size=64)\n",
    "\n",
    "ds_test = image_dataset_from_directory('../data/french_bird_db_25_100', labels='inferred', image_size=(300, 300), validation_split=0.2, subset=\"validation\",\n",
    "seed=42, label_mode = \"int\", color_mode = \"rgb\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes : 25\n"
     ]
    }
   ],
   "source": [
    "# Obtenir le nombre de classes à partir de ds\n",
    "class_names = ds_train.class_names\n",
    "num_classes = len(class_names)\n",
    "print('Nombre de classes :', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - loss: 17.8623 - sparse_categorical_accuracy: 0.0516 - val_loss: 16.9022 - val_sparse_categorical_accuracy: 0.0660\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 15.7710 - sparse_categorical_accuracy: 0.0789 - val_loss: 15.5655 - val_sparse_categorical_accuracy: 0.0580\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 14.9120 - sparse_categorical_accuracy: 0.0628 - val_loss: 14.9512 - val_sparse_categorical_accuracy: 0.0680\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 14.4181 - sparse_categorical_accuracy: 0.0944 - val_loss: 13.6411 - val_sparse_categorical_accuracy: 0.0720\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 13.8618 - sparse_categorical_accuracy: 0.0677 - val_loss: 12.9236 - val_sparse_categorical_accuracy: 0.0560\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 13.4132 - sparse_categorical_accuracy: 0.0574 - val_loss: 11.8508 - val_sparse_categorical_accuracy: 0.0460\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 12.8601 - sparse_categorical_accuracy: 0.0650 - val_loss: 11.0996 - val_sparse_categorical_accuracy: 0.0520\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - loss: 12.8485 - sparse_categorical_accuracy: 0.0701 - val_loss: 11.8607 - val_sparse_categorical_accuracy: 0.0480\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - loss: 12.5705 - sparse_categorical_accuracy: 0.0651 - val_loss: 11.6581 - val_sparse_categorical_accuracy: 0.0420\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - loss: 12.8864 - sparse_categorical_accuracy: 0.0671 - val_loss: 12.8563 - val_sparse_categorical_accuracy: 0.0560\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', pooling='avg', include_top=False, input_shape=(300, 300, 3), classes=num_classes)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Ajouter une couche de pooling global pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x_2 = Flatten()(x)\n",
    "# x_2 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x_3 = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x_2)\n",
    "# x_3 = Dense(num_classes, activation='relu')(x_2)\n",
    "x_3 = Dropout(0.5)(x_3)\n",
    "\n",
    "# Ajouter une couche dense pour effectuer la classification\n",
    "# output = Dense(num_classes, activation='softmax')(x_3)\n",
    "output = Dense(num_classes)(x_3)\n",
    "\n",
    "# Créer le modèle final en combinant le modèle de base et les couches supplémentaires\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# for layer in base_model.layers[-50:]:\n",
    "#     layer.compile(optimizer=Adam(learning_rate=0.0001))\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras.metrics.Accuracy()])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "             TensorBoard(log_dir='./logs/test', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "\n",
    "\n",
    "# Entraîner le modèle sur votre dataset avec le callback personnalisé\n",
    "\n",
    "history = model.fit(ds_train, epochs=10, callbacks=callbacks, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 729ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.778238, -13.052349, -13.387288, ..., -14.913307, -15.618199,\n",
       "        -21.230833],\n",
       "       [-19.352814, -17.803005, -15.527288, ..., -15.533906, -17.022852,\n",
       "        -22.432018],\n",
       "       [-17.347404, -13.440746, -13.041228, ..., -13.101124, -14.51528 ,\n",
       "        -20.279976],\n",
       "       ...,\n",
       "       [-29.381327, -22.51048 , -23.465921, ..., -24.112795, -25.175682,\n",
       "        -33.80227 ],\n",
       "       [-20.071695, -14.689756, -15.389884, ..., -15.727017, -16.208464,\n",
       "        -22.381783],\n",
       "       [-25.419542, -20.689138, -20.704712, ..., -20.56069 , -21.586573,\n",
       "        -29.447601]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[17 13  9 19 21 24  7 24 23 14 24 24 19 21  0 23  0 24 15  0 15 16 10 15\n",
      "  4 24 23  7  2  5 17 13  4  9 15  4 11 22 24 20 19  6 16 21  1 20 23  9\n",
      "  0 20 21  9 14  2 14 18 19 12  8  6 15 23 11 12], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 4  8 16  2  1 14 19 12  0 19  7 23 19 12  5  4  1  4  0 12 24 22  0  8\n",
      " 16 24 17 11 14  2 23 22  3  8  8 20  9 22  5 17 14 15 10 22 10 23 20 21\n",
      "  3  0 16 18  7  0 17 11  9 17  1  3  2 17 21  6], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[16 13  5 12 21 13 21 12  3  3 23 10 20  3 22 13 20 16  4  1  7 19 10  5\n",
      "  3 21 19 17 22 15  9 23 13  5 20 11 20  1 12  8 17 13 11  3 22 11 17 12\n",
      " 14 22 12 22 10  4 11 21 15 22 13 23  7 24  6 10], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[10 23 22  5 11  8  7 14 20 16  3 22 20 17 17  4  4  5 23  0 12 15 12 17\n",
      "  6  9  7  8 19 17 21 18  3  2  5  4 12  2  7 14  4  9 24 13  3 15 21  6\n",
      "  2 12 21 17  9 24 18  7 23  9], shape=(58,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 10:49:13.628887: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for image, label in ds_test:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:57:07.465560: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9, 13, 23,  7, 15, 15, 19,  6, 14, 14,  6, 24, 24,  1,  9,  7, 17,\n",
       "        0,  5, 19, 10, 21, 24, 19, 24, 17,  3, 24,  8,  4,  3, 21,  0, 21,\n",
       "        6, 10, 10,  9, 17, 12,  3, 14, 12, 11, 12,  0, 19, 14, 24,  3, 19,\n",
       "        2, 17,  7,  8,  4, 14, 17, 24, 11, 17, 13,  4,  0, 10,  0, 12,  3,\n",
       "       22,  2, 22, 11,  7,  5,  4,  6, 16,  2, 14,  5, 10, 20, 15,  3, 21,\n",
       "        2, 19, 16,  6, 23, 23, 13,  0, 12, 21,  8, 13,  5,  4, 22,  4, 11,\n",
       "       14,  3, 11,  0, 12,  9, 18,  0, 21, 23, 22, 19, 13, 10, 17, 16, 22,\n",
       "       22, 23, 15, 19, 10, 20, 24,  7,  8,  9, 11,  1, 15, 12,  4, 21,  3,\n",
       "       16, 17, 19, 18, 12,  8, 22,  7, 24, 24, 23,  2, 14,  4, 20, 20, 17,\n",
       "       22,  4, 17,  3, 22,  6,  1,  9,  2, 23,  9, 13,  7, 12, 24,  9,  7,\n",
       "        8, 12,  0,  4, 22,  2,  8,  4,  1, 21, 17, 13, 20, 23, 12,  5, 16,\n",
       "        5, 22, 12,  7, 15, 15, 19,  3, 17, 12, 17,  9, 10, 13,  9,  5,  3,\n",
       "       23, 20, 13, 22, 23, 22, 15, 24, 15, 11,  2, 12, 15,  5, 16,  7, 18,\n",
       "       21, 23,  4,  8,  1, 21, 17,  0, 20, 20, 14, 18,  5, 20, 20,  9, 20,\n",
       "       11, 21, 21, 11,  1, 23, 16, 17, 16, 21, 23, 23])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Définir une fonction pour extraire l'étiquette d'un élément du jeu de test\n",
    "def extract_label(image, label):\n",
    "    return label\n",
    "\n",
    "# Mapper chaque élément du jeu de test à son étiquette correspondante\n",
    "ds_test_labels = ds_test.map(extract_label)\n",
    "\n",
    "# Convertir le jeu de données en une liste d'étiquettes\n",
    "labels_list = list(ds_test_labels.unbatch())\n",
    "\n",
    "# Convertir la liste en tableau NumPy\n",
    "y_true = np.array(labels_list)\n",
    "\n",
    "# Convertir le tableau en entiers\n",
    "y_true = y_true.astype(np.int32)\n",
    "\n",
    "# Convertir le tableau one-hot en tableau d'indices entiers\n",
    "y_true_indices = np.argmax(y_true, axis=1)\n",
    "y_true_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 25)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2, 24,  3, 13,  2,  3,  5,  2, 13, 14, 13, 13,  9,  4, 19, 19,\n",
       "       13,  5,  5,  5, 19,  2, 19,  2, 13,  3, 14, 19, 13,  5, 19, 15, 12,\n",
       "       24,  2,  2, 19,  5, 13, 13,  0, 24,  0,  2,  1, 19,  1,  5, 13, 19,\n",
       "       15,  5,  2, 11, 19,  5,  5, 18, 13,  2, 24, 14, 19,  2, 10,  6,  2,\n",
       "       19,  3,  3,  3,  5,  7, 24, 18,  2, 13, 13,  2,  2, 13, 19, 19,  2,\n",
       "       19,  4, 19, 19, 19,  2,  5, 13, 19, 19, 13,  2,  2, 24,  2,  9, 19,\n",
       "       13,  2,  4,  8, 19, 19, 19, 24, 18, 13, 13, 19,  4,  5,  5,  2,  5,\n",
       "        5, 13,  5,  2,  3,  5, 19, 13,  4,  4, 24,  2,  8,  5, 13,  2,  5,\n",
       "       19,  5, 24, 18,  2,  4, 13, 19,  8, 19,  4, 24,  5,  2,  5, 13,  5,\n",
       "       19, 24, 19,  5,  2, 14, 13,  2, 13, 19, 19, 19,  4,  0,  2,  2, 19,\n",
       "        5, 13, 13, 14,  2,  5, 19, 13, 24, 19, 13, 19, 19,  5, 19, 24,  5,\n",
       "        3, 19, 19, 13, 19, 13,  2,  7, 18,  5, 19, 24, 24, 19,  5, 13,  2,\n",
       "       13, 13,  5, 13,  8, 14,  3, 13,  2,  2, 19, 13,  2,  3, 11,  8,  4,\n",
       "       13, 24, 18, 13, 11,  5, 13, 24, 18,  2, 24, 14,  7,  5, 11, 19, 13,\n",
       "        4,  2,  0, 13, 13,  9,  9,  5,  2, 24, 19,  5])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_vals = np.argmin(y_pred , axis=1)\n",
    "y_pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_true_indices, y_pred_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for accipiter_gentilis: 0.0000\n",
      "Precision for anthus_gustavi: 0.0000\n",
      "Precision for aquila_heliaca: 0.0000\n",
      "Precision for ardenna_griseus: 0.0909\n",
      "Precision for bombycilla_garrulus: 0.0000\n",
      "Precision for calidris_minutilla: 0.1111\n",
      "Precision for calidris_ruficollis: 0.0000\n",
      "Precision for chlidonias_leucopterus: 0.0000\n",
      "Precision for chlidonias_niger: 0.0000\n",
      "Precision for coccyzus_americanus: 0.0000\n",
      "Precision for glareola_nordmanni: 0.0000\n",
      "Precision for larus_argentatus: 0.0000\n",
      "Precision for leiothrix_lutea: 0.0000\n",
      "Precision for locustella_luscinioides: 0.0000\n",
      "Precision for motacilla_flava: 0.0000\n",
      "Precision for passer_italiae: 0.0000\n",
      "Precision for serinus_citrinella: 0.0000\n",
      "Precision for setophaga_fusca: 0.0000\n",
      "Precision for sitta_europaea: 0.2500\n",
      "Precision for streptopelia_decaocto: 0.4000\n",
      "Precision for sturnus_unicolor: 0.0000\n",
      "Precision for tringa_erythropus: 0.0000\n",
      "Precision for upupa_epops: 0.0000\n",
      "Precision for vanellus_vanellus: 0.0000\n",
      "Precision for zoothera_aurea: 0.0000\n"
     ]
    }
   ],
   "source": [
    "precision_by_class = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"Precision for {class_name}: {precision_by_class[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:30:44.617452: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step\n",
      "Precision for accipiter_gentilis: 0.0750\n",
      "Precision for anthus_gustavi: 0.0227\n",
      "Precision for aquila_heliaca: 0.0714\n",
      "Precision for ardenna_griseus: 0.0000\n",
      "Precision for bombycilla_garrulus: 0.0526\n",
      "Precision for calidris_minutilla: 0.0732\n",
      "Precision for calidris_ruficollis: 0.0682\n",
      "Precision for chlidonias_leucopterus: 0.0000\n",
      "Precision for chlidonias_niger: 0.0476\n",
      "Precision for coccyzus_americanus: 0.0256\n",
      "Precision for glareola_nordmanni: 0.0714\n",
      "Precision for larus_argentatus: 0.0000\n",
      "Precision for leiothrix_lutea: 0.0000\n",
      "Precision for locustella_luscinioides: 0.0488\n",
      "Precision for motacilla_flava: 0.0244\n",
      "Precision for passer_italiae: 0.0250\n",
      "Precision for serinus_citrinella: 0.0476\n",
      "Precision for setophaga_fusca: 0.0286\n",
      "Precision for sitta_europaea: 0.0217\n",
      "Precision for streptopelia_decaocto: 0.0000\n",
      "Precision for sturnus_unicolor: 0.0000\n",
      "Precision for tringa_erythropus: 0.0270\n",
      "Precision for upupa_epops: 0.0811\n",
      "Precision for vanellus_vanellus: 0.0278\n",
      "Precision for zoothera_aurea: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Définir une fonction pour extraire l'étiquette d'un élément du jeu de test\n",
    "def extract_label(image, label):\n",
    "    return label\n",
    "\n",
    "# Mapper chaque élément du jeu de test à son étiquette correspondante\n",
    "ds_train_labels_train = ds_train.map(extract_label)\n",
    "\n",
    "# Convertir le jeu de données en une liste d'étiquettes\n",
    "labels_list_train = list(ds_train_labels_train.unbatch())\n",
    "\n",
    "# Convertir la liste en tableau NumPy\n",
    "y_true_train = np.array(labels_list_train)\n",
    "\n",
    "# Convertir le tableau en entiers\n",
    "y_true_train = y_true_train.astype(np.int32)\n",
    "\n",
    "# Convertir le tableau one-hot en tableau d'indices entiers\n",
    "y_true_indices_train = np.argmax(y_true_train, axis=1)\n",
    "\n",
    "y_pred_train = model.predict(ds_train)\n",
    "y_pred_vals_train = np.argmax(y_pred_train , axis=1)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y_true_indices_train, y_pred_vals_train)\n",
    "\n",
    "precision_by_class_train = conf_matrix_train.diagonal() / conf_matrix_train.sum(axis=1)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"Precision for {class_name}: {precision_by_class_train[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5, 12, 24, 11, 13,  5,  3, 22,  2, 22, 20,  8, 21,  3,  7, 23,\n",
       "       23,  6,  6, 24, 17, 24, 23,  5, 10,  0, 20, 21,  0, 20, 15,  0, 16,\n",
       "        2, 17,  4,  9,  7, 23, 22,  9, 16, 12,  9, 16, 10, 22,  4,  4, 22,\n",
       "       11, 17, 11, 23, 11, 21,  9, 24, 22,  6,  8,  3, 21, 15, 16, 21,  7,\n",
       "       14, 19, 16,  6, 11, 21,  0, 19, 24, 11, 12, 14,  2, 23, 17,  6, 24,\n",
       "       12, 13, 17, 19,  4, 21, 14,  0, 22,  0, 20,  7,  5, 14, 19, 13, 14,\n",
       "        0, 12,  1, 19, 22, 24, 22, 12, 14,  5, 12, 21,  5,  5,  7,  4,  7,\n",
       "       21, 12,  0,  4, 17, 17,  9, 22,  6, 11, 12, 17, 22, 20, 21, 16, 23,\n",
       "       23, 11,  2, 19, 15,  8, 11, 22, 20,  4, 15,  1,  9, 23, 12,  5,  3,\n",
       "       15,  1,  3, 17, 14, 12, 18, 17, 20, 13, 10, 10, 10, 18, 13, 19, 12,\n",
       "        3,  3, 17,  1, 15, 14,  7, 21, 20, 14, 13, 18,  4, 20, 15, 20, 12,\n",
       "        4, 20,  8, 13, 21, 15,  3,  2,  9,  0, 18, 24,  4, 12,  9,  3, 10,\n",
       "       17, 24,  9, 24, 24,  7, 17,  8,  4,  8,  8, 16, 17, 19,  2, 15, 23,\n",
       "       10, 21, 17, 23,  7, 23, 15,  5, 23, 13,  3,  8,  9,  4, 24, 19,  0,\n",
       "        7, 22,  1,  2,  2, 19,  1, 13, 10, 23, 16,  9])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 19, 15, 11,  0,  8, 22, 20, 17, 11,  4,  5,  1, 22, 12, 16, 21,\n",
       "        0, 23, 16,  1,  6, 16,  9, 12, 12, 15, 23,  3, 24, 12,  1,  4,  4,\n",
       "        7,  4, 20,  6,  0, 20, 22,  6,  2, 22,  4, 11, 22, 21, 21, 18, 19,\n",
       "       12, 24, 20, 15,  7, 23,  9, 11, 21, 18,  5, 11, 15, 23,  6, 15, 17,\n",
       "        6,  2, 16, 21, 15,  1,  1, 20, 15, 21,  4, 15, 15,  4, 18, 15, 11,\n",
       "        8, 22, 12, 24,  3, 23, 11, 19, 23,  1, 16, 17, 11,  6,  7,  3,  3,\n",
       "        6, 10,  4,  9, 21, 24, 14,  3, 13, 12,  3, 14, 12, 24, 13, 20, 21,\n",
       "       23, 21, 20, 14, 24,  3, 22, 17,  0,  4,  4,  1, 21, 15, 22,  7, 13,\n",
       "       17, 17, 18,  7, 19, 15, 12, 21, 14, 14,  6,  2, 12,  6, 21, 21, 15,\n",
       "       22,  7,  0,  9,  0, 22, 12, 19, 21,  9, 24, 12, 16, 24, 10, 12,  6,\n",
       "       17,  7,  7, 20, 21, 10,  7, 16, 15,  9,  0, 17,  5, 18, 15, 16, 24,\n",
       "        6,  3,  2, 10, 11,  3,  8, 12, 10, 24, 18,  3, 13, 15, 19,  4,  7,\n",
       "        0, 16, 10, 15,  8, 11,  7, 17, 12,  1, 19,  4, 21, 15, 11, 10, 24,\n",
       "        3, 10, 23, 15, 22, 18,  5,  9,  8, 19, 13,  5, 15, 11,  1,  1,  4,\n",
       "        2, 15,  2,  9, 12,  4,  5,  1, 22,  6, 13, 24])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18482682, 0.766139  , 0.40718135, 0.5508109 , 0.43335474,\n",
       "       0.19126093, 0.5704572 , 0.5914626 , 0.31461933, 0.44886157,\n",
       "       0.3269929 , 0.25726274, 0.14607272, 0.66678345, 0.29069877,\n",
       "       0.5182274 , 0.5730148 , 0.96231514, 0.3100958 , 0.2049834 ,\n",
       "       0.5415791 , 0.4239429 , 0.7734938 , 0.40044728, 0.49171168,\n",
       "       0.45559797, 0.15411632, 0.35458413, 0.49406296, 0.6108449 ,\n",
       "       0.50771594, 0.5720814 , 0.7895284 , 0.46853408, 0.37861973,\n",
       "       0.9981717 , 0.25189844, 0.5605948 , 0.76084614, 0.18183681,\n",
       "       0.8424699 , 0.49105638, 0.44601095, 0.42153543, 0.859926  ,\n",
       "       0.77729416, 0.8429477 , 0.8261464 , 0.48235112, 0.4507751 ,\n",
       "       0.6629946 , 0.48601064, 0.55220973, 0.23016056, 0.21335825,\n",
       "       0.31973797, 0.45896032, 0.5113065 , 0.7057979 , 0.29227448,\n",
       "       0.850246  , 0.6891459 , 0.43082473, 0.40914848, 0.1803795 ,\n",
       "       0.30801868, 0.40946198, 0.41172358, 0.37524137, 0.69713503,\n",
       "       0.39592525, 0.7511595 , 0.6687855 , 0.38747188, 0.10940367,\n",
       "       0.51539564, 0.5036669 , 0.6063102 , 0.9518966 , 0.32021168,\n",
       "       0.18917476, 0.24058257, 0.26333624, 0.2883109 , 0.22897992,\n",
       "       0.2136718 , 0.1928514 , 0.24924205, 0.6105584 , 0.42868704,\n",
       "       0.38480884, 0.2917299 , 0.9117851 , 0.25340226, 0.38125435,\n",
       "       0.39889437, 0.21147868, 0.36194316, 0.30155572, 0.35380092,\n",
       "       0.24912062, 0.89654493, 0.42496803, 0.207464  , 0.795011  ,\n",
       "       0.5630986 , 0.5987039 , 0.49466506, 0.18310474, 0.8964397 ,\n",
       "       0.9251879 , 0.4048209 , 0.5502836 , 0.5473417 , 0.76784563,\n",
       "       0.50841147, 0.9412938 , 0.53488857, 0.44921872, 0.41336063,\n",
       "       0.8527048 , 0.24340238, 0.56424916, 0.9022364 , 0.96040726,\n",
       "       0.69699   , 0.2400466 , 0.8216773 , 0.80768234, 0.26552176,\n",
       "       0.4003555 , 0.35998437, 0.30526602, 0.51220125, 0.5832131 ,\n",
       "       0.7142118 , 0.3650465 , 0.2398362 , 0.5659487 , 0.21186417,\n",
       "       0.84296894, 0.45439816, 0.478132  , 0.3036657 , 0.6219441 ,\n",
       "       0.2436949 , 0.2842003 , 0.44632876, 0.28820866, 0.16541559,\n",
       "       0.17900082, 0.85886496, 0.6906347 , 0.58487123, 0.3184943 ,\n",
       "       0.37579685, 0.33270785, 0.8874716 , 0.7607145 , 0.5401362 ,\n",
       "       0.7056371 , 0.34948322, 0.41852915, 0.25766048, 0.49429265,\n",
       "       0.31531185, 0.92530125, 0.36906478, 0.20129743, 0.11488768,\n",
       "       0.40240735, 0.6267815 , 0.2570685 , 0.13920511, 0.48237103,\n",
       "       0.7376707 , 0.14761724, 0.586373  , 0.17556298, 0.36701012,\n",
       "       0.33979145, 0.34945533, 0.58632064, 0.30787796, 0.5142399 ,\n",
       "       0.27617723, 0.7340465 , 0.18784706, 0.3881371 , 0.2086366 ,\n",
       "       0.3174507 , 0.9290634 , 0.42770508, 0.2961811 , 0.32454133,\n",
       "       0.29511204, 0.8046423 , 0.16908884, 0.27688742, 0.30469188,\n",
       "       0.26915565, 0.96442276, 0.5986205 , 0.36917043, 0.93997127,\n",
       "       0.33859482, 0.30040848, 0.28853047, 0.33972248, 0.39882612,\n",
       "       0.3246202 , 0.5181543 , 0.42583573, 0.64373654, 0.4474488 ,\n",
       "       0.6062881 , 0.18987048, 0.4066725 , 0.72511774, 0.24249758,\n",
       "       0.49488923, 0.91012526, 0.41460437, 0.21329843, 0.2261311 ,\n",
       "       0.30889878, 0.94120383, 0.4434178 , 0.45486686, 0.3817484 ,\n",
       "       0.26364636, 0.3711612 , 0.19743751, 0.32509777, 0.4813107 ,\n",
       "       0.531592  , 0.2483178 , 0.73103535, 0.7967006 , 0.43234938,\n",
       "       0.35107765, 0.49706718, 0.5285719 , 0.36376238, 0.3948714 ,\n",
       "       0.5479683 , 0.6513125 , 0.34899196, 0.16408144, 0.65198   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_maxs = np.max(y_pred , axis=1)\n",
    "y_pred_maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.18105507e-04, 1.90391547e-05, 2.98207010e-06, 1.24975760e-03,\n",
       "       2.60099318e-06, 4.27163264e-04, 3.67723769e-05, 4.36370639e-04,\n",
       "       2.38516054e-06, 2.91418401e-04, 1.29068867e-05, 2.87874747e-04,\n",
       "       4.64283570e-04, 1.53145680e-04, 1.51726963e-05, 5.88027888e-06,\n",
       "       5.28315977e-05, 1.78986966e-07, 7.85276461e-06, 1.15060888e-04,\n",
       "       1.26424464e-04, 4.34647409e-05, 1.23874934e-05, 2.52328377e-04,\n",
       "       8.09007761e-05, 3.03663091e-06, 2.80956249e-03, 5.10462705e-05,\n",
       "       1.31391600e-04, 2.60318222e-04, 4.27472924e-06, 3.38105428e-06,\n",
       "       1.77806487e-05, 9.70385227e-05, 3.98393495e-05, 1.02965245e-08,\n",
       "       1.45072991e-04, 1.20744812e-06, 8.65350812e-05, 1.91750180e-04,\n",
       "       6.37754565e-05, 1.18383775e-06, 4.59526782e-05, 1.61655742e-04,\n",
       "       1.80150471e-06, 9.04365788e-06, 6.17569385e-05, 5.91332082e-06,\n",
       "       3.71361020e-05, 1.03325714e-04, 9.90554181e-05, 1.74741162e-05,\n",
       "       1.01778081e-04, 5.13874053e-04, 2.59143487e-03, 5.18155730e-06,\n",
       "       9.19326121e-05, 4.01033612e-05, 1.99138373e-03, 5.33071347e-04,\n",
       "       1.89305229e-05, 9.06256810e-06, 1.76757225e-04, 9.86859552e-04,\n",
       "       5.62283676e-05, 6.67035238e-06, 1.16767094e-03, 3.84168343e-05,\n",
       "       3.72337490e-05, 2.23740449e-06, 4.91186483e-06, 1.37292068e-06,\n",
       "       9.81520207e-05, 4.92277877e-06, 6.20378740e-03, 2.44939409e-04,\n",
       "       1.24697253e-04, 1.29317459e-05, 7.73325155e-06, 4.48430888e-04,\n",
       "       4.12436755e-04, 1.59208744e-03, 3.89261040e-05, 1.06520287e-03,\n",
       "       6.16895501e-04, 5.91299868e-05, 1.76753354e-04, 4.04994717e-05,\n",
       "       1.51383763e-04, 2.42637925e-05, 1.07997295e-03, 1.30392914e-03,\n",
       "       2.48418291e-05, 1.20249309e-03, 2.10519996e-04, 1.64112542e-04,\n",
       "       7.49391271e-04, 3.99577875e-05, 7.51680182e-06, 2.66733899e-04,\n",
       "       2.77683444e-06, 3.33728536e-07, 7.16754948e-05, 1.00844263e-04,\n",
       "       6.75988340e-05, 5.17427470e-05, 1.16667061e-05, 9.71886839e-05,\n",
       "       4.78416710e-04, 9.61521255e-06, 1.98648195e-06, 7.22740078e-05,\n",
       "       7.51506923e-06, 6.55333351e-05, 2.97908900e-06, 1.76800284e-04,\n",
       "       3.43711797e-08, 1.13793074e-04, 3.06884940e-05, 4.28480038e-04,\n",
       "       4.51122878e-06, 5.36089647e-04, 8.68532807e-05, 4.69247680e-05,\n",
       "       3.85514284e-07, 2.55885127e-04, 1.58145427e-04, 1.48394889e-07,\n",
       "       3.15356483e-05, 1.39097028e-04, 2.37052573e-05, 3.57820791e-05,\n",
       "       1.68607850e-03, 2.73087353e-04, 5.00181613e-06, 1.38128453e-04,\n",
       "       4.59304392e-05, 4.12473637e-05, 3.06464324e-04, 5.91816672e-04,\n",
       "       2.81352259e-05, 9.23355765e-06, 3.79801095e-05, 2.26180709e-05,\n",
       "       1.24817052e-05, 1.12756086e-03, 7.12796973e-05, 2.46863306e-06,\n",
       "       6.00166386e-05, 1.77943497e-03, 3.08171671e-04, 7.19150830e-06,\n",
       "       5.64330264e-07, 9.56263466e-05, 1.14320748e-04, 1.17801224e-04,\n",
       "       1.54604830e-04, 2.10406697e-07, 9.34035415e-05, 1.11241015e-05,\n",
       "       4.13287897e-04, 1.83364216e-04, 7.73312513e-06, 1.89677041e-04,\n",
       "       1.38688256e-05, 2.47686803e-05, 5.51685571e-06, 2.08343554e-04,\n",
       "       8.58047686e-04, 1.43650209e-03, 1.83587474e-06, 3.01226992e-05,\n",
       "       2.16927700e-04, 1.42457325e-03, 7.87155295e-06, 1.34262436e-05,\n",
       "       1.01523721e-04, 4.05475803e-05, 1.50584255e-03, 2.47839544e-05,\n",
       "       7.52287960e-05, 9.67214601e-06, 1.53990666e-04, 1.41039141e-04,\n",
       "       1.43266210e-04, 2.79813976e-05, 1.03356142e-04, 1.60371725e-04,\n",
       "       2.44822411e-04, 3.52474488e-03, 6.00556887e-05, 6.47231864e-05,\n",
       "       6.13155935e-05, 5.91974385e-05, 1.10640701e-06, 1.05987373e-03,\n",
       "       1.42083925e-04, 2.13317387e-03, 4.21311688e-06, 1.02662412e-03,\n",
       "       5.15002175e-04, 3.03199272e-06, 4.88449696e-05, 1.46742223e-05,\n",
       "       5.11154269e-07, 4.22654921e-05, 1.37692641e-05, 3.24521377e-03,\n",
       "       1.52407074e-05, 2.67756586e-05, 1.72525673e-04, 2.31052782e-05,\n",
       "       4.59811490e-05, 1.28282027e-05, 9.44274216e-05, 7.62940472e-05,\n",
       "       9.46117798e-05, 9.85041243e-06, 2.68173171e-04, 3.50398535e-04,\n",
       "       1.49379877e-04, 2.46957399e-07, 1.69734703e-04, 5.37483138e-04,\n",
       "       8.37229745e-05, 3.66408465e-04, 1.34509230e-06, 3.55599041e-04,\n",
       "       9.01989115e-05, 6.82795828e-04, 2.39485735e-03, 2.60751636e-04,\n",
       "       2.31053983e-03, 8.79557454e-04, 5.51213103e-04, 2.56775616e-04,\n",
       "       5.06463111e-04, 4.13199195e-05, 2.99643648e-06, 2.23427105e-05,\n",
       "       1.66890473e-04, 2.59385820e-06, 5.03156753e-06, 1.42375175e-05,\n",
       "       1.29944878e-04, 2.23837807e-04, 3.15639627e-05, 1.22569718e-05,\n",
       "       3.75155068e-05, 3.33538541e-04], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mins = np.min(y_pred , axis=1)\n",
    "y_pred_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  5,  2, 13, 14, 19,  3,  4,  3,  9,  5, 13,  0, 19, 24,  2, 19,\n",
       "       13, 19, 11,  8, 19,  2,  4,  5,  2,  3, 19, 13, 13,  2,  2,  5,  5,\n",
       "       13,  5, 14, 19,  5,  4,  3, 19, 14,  5,  5, 13,  5, 19, 13, 24,  5,\n",
       "       24, 13, 24,  2, 19, 19,  3, 18, 13, 19, 19,  5,  2,  5, 19,  2,  2,\n",
       "       19,  4,  2, 13,  2,  2,  2, 24,  7, 13,  5,  2,  5,  0, 24,  5, 13,\n",
       "       13, 18,  2, 13, 19, 15,  1,  5, 24,  2,  2,  2,  9, 19, 13, 19, 13,\n",
       "       19, 19,  5,  8, 19, 13,  0, 13,  5,  2,  9, 24,  5, 13,  7,  4, 19,\n",
       "       19, 13, 19,  2, 14, 13,  5, 19,  4,  2, 18,  8, 19,  0, 19, 19,  3,\n",
       "       24,  2, 24, 13,  5,  2,  8, 13, 24,  3, 19,  4,  5, 11, 13, 19,  5,\n",
       "        3, 19, 13,  7, 14, 18,  5,  6, 19, 24, 13,  5, 24, 14,  1,  4, 19,\n",
       "        2, 19, 13, 11, 19,  9, 13,  2,  5, 24,  4,  2, 19, 19,  2,  2, 18,\n",
       "       19, 13,  4, 13, 13, 13, 13, 24, 19, 18, 10, 13,  5,  2,  5,  5, 19,\n",
       "       13,  2, 13,  5, 19, 13, 19,  2,  5,  3,  5,  2,  2, 24, 13, 19, 13,\n",
       "       13, 19, 15,  5,  5, 24, 13,  3, 19,  2, 24, 19,  2, 13,  2,  8,  2,\n",
       "       14,  2,  4,  2,  2, 19, 13, 11,  5, 19, 24, 12])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_indice_mins = np.argmin(y_pred , axis=1)\n",
    "y_pred_indice_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5, 12, 24, 11, 13,  5,  3, 22,  2, 22, 20,  8, 21,  3,  7, 23,\n",
       "       23,  6,  6, 24, 17, 24, 23,  5, 10,  0, 20, 21,  0, 20, 15,  0, 16,\n",
       "        2, 17,  4,  9,  7, 23, 22,  9, 16, 12,  9, 16, 10, 22,  4,  4, 22,\n",
       "       11, 17, 11, 23, 11, 21,  9, 24, 22,  6,  8,  3, 21, 15, 16, 21,  7,\n",
       "       14, 19, 16,  6, 11, 21,  0, 19, 24, 11, 12, 14,  2, 23, 17,  6, 24,\n",
       "       12, 13, 17, 19,  4, 21, 14,  0, 22,  0, 20,  7,  5, 14, 19, 13, 14,\n",
       "        0, 12,  1, 19, 22, 24, 22, 12, 14,  5, 12, 21,  5,  5,  7,  4,  7,\n",
       "       21, 12,  0,  4, 17, 17,  9, 22,  6, 11, 12, 17, 22, 20, 21, 16, 23,\n",
       "       23, 11,  2, 19, 15,  8, 11, 22, 20,  4, 15,  1,  9, 23, 12,  5,  3,\n",
       "       15,  1,  3, 17, 14, 12, 18, 17, 20, 13, 10, 10, 10, 18, 13, 19, 12,\n",
       "        3,  3, 17,  1, 15, 14,  7, 21, 20, 14, 13, 18,  4, 20, 15, 20, 12,\n",
       "        4, 20,  8, 13, 21, 15,  3,  2,  9,  0, 18, 24,  4, 12,  9,  3, 10,\n",
       "       17, 24,  9, 24, 24,  7, 17,  8,  4,  8,  8, 16, 17, 19,  2, 15, 23,\n",
       "       10, 21, 17, 23,  7, 23, 15,  5, 23, 13,  3,  8,  9,  4, 24, 19,  0,\n",
       "        7, 22,  1,  2,  2, 19,  1, 13, 10, 23, 16,  9])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15254582, 0.11740228, 0.02156574, 0.00061973, 0.01274756,\n",
       "       0.00151492, 0.00352224, 0.00163642, 0.00096756, 0.15143108,\n",
       "       0.01321595, 0.00315627, 0.00434744, 0.01014561, 0.00036471,\n",
       "       0.03170317, 0.06439347, 0.00560139, 0.00031811, 0.07844228,\n",
       "       0.01199207, 0.04263559, 0.08227933, 0.00262443, 0.18482682],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5, 12, 24, 11, 13,  5,  3, 22,  2, 22, 20,  8, 21,  3,  7, 23,\n",
       "       23,  6,  6, 24, 17, 24, 23,  5, 10,  0, 20, 21,  0, 20, 15,  0, 16,\n",
       "        2, 17,  4,  9,  7, 23, 22,  9, 16, 12,  9, 16, 10, 22,  4,  4, 22,\n",
       "       11, 17, 11, 23, 11, 21,  9, 24, 22,  6,  8,  3, 21, 15, 16, 21,  7,\n",
       "       14, 19, 16,  6, 11, 21,  0, 19, 24, 11, 12, 14,  2, 23, 17,  6, 24,\n",
       "       12, 13, 17, 19,  4, 21, 14,  0, 22,  0, 20,  7,  5, 14, 19, 13, 14,\n",
       "        0, 12,  1, 19, 22, 24, 22, 12, 14,  5, 12, 21,  5,  5,  7,  4,  7,\n",
       "       21, 12,  0,  4, 17, 17,  9, 22,  6, 11, 12, 17, 22, 20, 21, 16, 23,\n",
       "       23, 11,  2, 19, 15,  8, 11, 22, 20,  4, 15,  1,  9, 23, 12,  5,  3,\n",
       "       15,  1,  3, 17, 14, 12, 18, 17, 20, 13, 10, 10, 10, 18, 13, 19, 12,\n",
       "        3,  3, 17,  1, 15, 14,  7, 21, 20, 14, 13, 18,  4, 20, 15, 20, 12,\n",
       "        4, 20,  8, 13, 21, 15,  3,  2,  9,  0, 18, 24,  4, 12,  9,  3, 10,\n",
       "       17, 24,  9, 24, 24,  7, 17,  8,  4,  8,  8, 16, 17, 19,  2, 15, 23,\n",
       "       10, 21, 17, 23,  7, 23, 15,  5, 23, 13,  3,  8,  9,  4, 24, 19,  0,\n",
       "        7, 22,  1,  2,  2, 19,  1, 13, 10, 23, 16,  9])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_real = np.zeros(250)\n",
    "\n",
    "for i, pred_val in enumerate(y_pred):\n",
    "   real_indice = y_true_indices[i]\n",
    "   val_vector_real = pred_val[real_indice]\n",
    "   vectors_real[i] = val_vector_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.0006197260809130967, 18, 0.0003181055)\n",
      "(5, 1.9039154722122476e-05, 5, 1.9039155e-05)\n",
      "(12, 0.14681969583034515, 2, 2.98207e-06)\n",
      "(24, 0.008126943372189999, 13, 0.0012497576)\n",
      "(11, 0.005510981660336256, 14, 2.6009932e-06)\n",
      "(13, 0.0028871081303805113, 19, 0.00042716326)\n",
      "(5, 9.473284444538876e-05, 3, 3.6772377e-05)\n",
      "(3, 0.08599788695573807, 4, 0.00043637064)\n",
      "(22, 0.04597420617938042, 3, 2.3851605e-06)\n",
      "(2, 0.00993955135345459, 9, 0.0002914184)\n",
      "(22, 0.006613728124648333, 5, 1.2906887e-05)\n",
      "(20, 0.01867377571761608, 13, 0.00028787475)\n",
      "(8, 0.009861847385764122, 0, 0.00046428357)\n",
      "(21, 0.04510961472988129, 19, 0.00015314568)\n",
      "(3, 0.0003744135901797563, 24, 1.5172696e-05)\n",
      "(7, 0.00026907146093435585, 2, 5.880279e-06)\n",
      "(23, 0.0057215820997953415, 19, 5.2831598e-05)\n",
      "(23, 5.704015165974852e-06, 13, 1.7898697e-07)\n",
      "(6, 0.27942100167274475, 19, 7.852765e-06)\n",
      "(6, 0.1680084615945816, 11, 0.00011506089)\n",
      "(24, 0.03262096643447876, 8, 0.00012642446)\n",
      "(17, 0.011096153408288956, 19, 4.346474e-05)\n",
      "(24, 0.00017933417984750122, 2, 1.2387493e-05)\n",
      "(23, 0.008945353329181671, 4, 0.00025232838)\n",
      "(5, 8.090077608358115e-05, 5, 8.0900776e-05)\n",
      "(10, 1.9081757272942923e-05, 2, 3.036631e-06)\n",
      "(0, 0.005292712710797787, 3, 0.0028095625)\n",
      "(20, 0.014968653209507465, 19, 5.104627e-05)\n",
      "(21, 0.00964570976793766, 13, 0.0001313916)\n",
      "(0, 0.008913862518966198, 13, 0.00026031822)\n",
      "(20, 0.00013305447646416724, 2, 4.2747292e-06)\n",
      "(15, 0.07094526290893555, 2, 3.3810543e-06)\n",
      "(0, 0.002117984462529421, 5, 1.7780649e-05)\n",
      "(16, 0.0028030574321746826, 5, 9.703852e-05)\n",
      "(2, 0.021581849083304405, 13, 3.983935e-05)\n",
      "(17, 1.3228781199359219e-06, 5, 1.02965245e-08)\n",
      "(4, 0.00015605034423060715, 14, 0.00014507299)\n",
      "(9, 0.0010909101692959666, 19, 1.2074481e-06)\n",
      "(7, 0.0015880281571298838, 5, 8.653508e-05)\n",
      "(23, 0.02546084113419056, 4, 0.00019175018)\n",
      "(22, 0.8424698710441589, 3, 6.377546e-05)\n",
      "(9, 0.006524510215967894, 19, 1.1838378e-06)\n",
      "(16, 0.007359538227319717, 14, 4.595268e-05)\n",
      "(12, 0.008536896668374538, 5, 0.00016165574)\n",
      "(9, 0.0008745491504669189, 5, 1.8015047e-06)\n",
      "(16, 0.00300548761151731, 13, 9.043658e-06)\n",
      "(10, 0.015561558306217194, 5, 6.175694e-05)\n",
      "(22, 0.0017813446465879679, 19, 5.913321e-06)\n",
      "(4, 0.0015149143291637301, 13, 3.7136102e-05)\n",
      "(4, 0.0011355445021763444, 24, 0.000103325714)\n",
      "(22, 0.015081938356161118, 5, 9.905542e-05)\n",
      "(11, 0.00034399345167912543, 24, 1.7474116e-05)\n",
      "(17, 0.0024638636969029903, 13, 0.00010177808)\n",
      "(11, 0.001816687174141407, 24, 0.00051387405)\n",
      "(23, 0.017455317080020905, 2, 0.0025914349)\n",
      "(11, 0.029544241726398468, 19, 5.1815573e-06)\n",
      "(21, 0.005553384777158499, 19, 9.193261e-05)\n",
      "(9, 0.5113065242767334, 3, 4.010336e-05)\n",
      "(24, 0.013709061779081821, 18, 0.0019913837)\n",
      "(22, 0.0036252185236662626, 13, 0.00053307135)\n",
      "(6, 0.0007906444952823222, 19, 1.8930523e-05)\n",
      "(8, 0.012005605734884739, 19, 9.062568e-06)\n",
      "(3, 0.006647184956818819, 5, 0.00017675722)\n",
      "(21, 0.005988303571939468, 2, 0.0009868596)\n",
      "(15, 0.042761240154504776, 5, 5.6228368e-05)\n",
      "(16, 0.009976712986826897, 19, 6.6703524e-06)\n",
      "(21, 0.02413814887404442, 2, 0.0011676709)\n",
      "(7, 0.0025472198612987995, 2, 3.8416834e-05)\n",
      "(14, 0.009360848926007748, 19, 3.723375e-05)\n",
      "(19, 0.0002531444770283997, 4, 2.2374045e-06)\n",
      "(16, 0.39592525362968445, 2, 4.911865e-06)\n",
      "(6, 0.0009078178554773331, 13, 1.3729207e-06)\n",
      "(11, 0.0035162109415978193, 2, 9.815202e-05)\n",
      "(21, 0.0030785822309553623, 2, 4.9227788e-06)\n",
      "(0, 0.01539839431643486, 2, 0.0062037874)\n",
      "(19, 0.0035253604874014854, 24, 0.0002449394)\n",
      "(24, 0.0006294616614468396, 7, 0.00012469725)\n",
      "(11, 0.007107362616807222, 13, 1.2931746e-05)\n",
      "(12, 0.0007394161075353622, 5, 7.733252e-06)\n",
      "(14, 0.05371522903442383, 2, 0.0004484309)\n",
      "(2, 0.005832949187606573, 5, 0.00041243676)\n",
      "(23, 0.08888443559408188, 0, 0.0015920874)\n",
      "(17, 0.024163080379366875, 24, 3.8926104e-05)\n",
      "(6, 0.026254625990986824, 5, 0.0010652029)\n",
      "(24, 0.004001928493380547, 13, 0.0006168955)\n",
      "(12, 0.0011898649390786886, 13, 5.9129987e-05)\n",
      "(13, 0.008002720773220062, 18, 0.00017675335)\n",
      "(17, 0.017512571066617966, 2, 4.049947e-05)\n",
      "(19, 0.010265239514410496, 13, 0.00015138376)\n",
      "(4, 0.004086026921868324, 19, 2.4263793e-05)\n",
      "(21, 0.019214510917663574, 15, 0.001079973)\n",
      "(14, 0.00782369077205658, 1, 0.0013039291)\n",
      "(0, 0.006855678278952837, 5, 2.484183e-05)\n",
      "(22, 0.0696023479104042, 24, 0.0012024931)\n",
      "(0, 0.004927101079374552, 2, 0.00021052)\n",
      "(20, 0.002372919348999858, 2, 0.00016411254)\n",
      "(7, 0.006052871700376272, 2, 0.00074939127)\n",
      "(5, 0.0009067992214113474, 9, 3.9957788e-05)\n",
      "(14, 0.007053110282868147, 19, 7.516802e-06)\n",
      "(19, 0.00026971095940098166, 13, 0.0002667339)\n",
      "(13, 0.00024955274420790374, 19, 2.7768344e-06)\n",
      "(14, 3.968767850892618e-05, 13, 3.3372854e-07)\n",
      "(0, 0.0001416262675775215, 19, 7.1675495e-05)\n",
      "(12, 0.005883941426873207, 19, 0.00010084426)\n",
      "(1, 0.0017779121408239007, 5, 6.7598834e-05)\n",
      "(19, 0.00675203837454319, 8, 5.1742747e-05)\n",
      "(22, 0.004383436869829893, 19, 1.1666706e-05)\n",
      "(24, 0.4946650564670563, 13, 9.7188684e-05)\n",
      "(22, 0.02063046209514141, 0, 0.0004784167)\n",
      "(12, 0.0018337039509788156, 13, 9.615213e-06)\n",
      "(14, 0.0035647740587592125, 5, 1.986482e-06)\n",
      "(5, 0.0005261637852527201, 2, 7.227401e-05)\n",
      "(12, 0.0008343085646629333, 9, 7.5150692e-06)\n",
      "(21, 0.008793632499873638, 24, 6.5533335e-05)\n",
      "(5, 2.9790890039294027e-06, 5, 2.979089e-06)\n",
      "(5, 0.11928943544626236, 13, 0.00017680028)\n",
      "(7, 3.4371179680192654e-08, 7, 3.437118e-08)\n",
      "(4, 0.00011379307397874072, 4, 0.000113793074)\n",
      "(7, 0.024833930656313896, 19, 3.0688494e-05)\n",
      "(21, 0.040529146790504456, 19, 0.00042848004)\n",
      "(12, 0.00012356994557194412, 13, 4.511229e-06)\n",
      "(0, 0.011400748044252396, 19, 0.00053608965)\n",
      "(4, 0.01747243106365204, 2, 8.685328e-05)\n",
      "(17, 0.00021801503316964954, 14, 4.6924768e-05)\n",
      "(17, 3.7341051211114973e-06, 13, 3.8551428e-07)\n",
      "(9, 0.008989092893898487, 5, 0.00025588513)\n",
      "(22, 0.007144479546695948, 19, 0.00015814543)\n",
      "(6, 1.625662116566673e-05, 4, 1.4839489e-07)\n",
      "(11, 0.03062620759010315, 2, 3.153565e-05)\n",
      "(12, 0.004193166736513376, 18, 0.00013909703)\n",
      "(17, 0.13812553882598877, 8, 2.3705257e-05)\n",
      "(22, 0.0037218229845166206, 19, 3.578208e-05)\n",
      "(20, 0.09480307996273041, 0, 0.0016860785)\n",
      "(21, 0.04817852005362511, 19, 0.00027308735)\n",
      "(16, 0.0016541925724595785, 19, 5.001816e-06)\n",
      "(23, 0.024642348289489746, 3, 0.00013812845)\n",
      "(23, 0.005354721564799547, 24, 4.593044e-05)\n",
      "(11, 0.0017345149535685778, 2, 4.1247364e-05)\n",
      "(2, 0.008841476403176785, 24, 0.00030646432)\n",
      "(19, 0.0188456904143095, 13, 0.0005918167)\n",
      "(15, 0.0351170189678669, 5, 2.8135226e-05)\n",
      "(8, 0.0010263610165566206, 2, 9.233558e-06)\n",
      "(11, 0.0006009871140122414, 8, 3.798011e-05)\n",
      "(22, 0.0005391348386183381, 13, 2.2618071e-05)\n",
      "(20, 0.0005336626200005412, 24, 1.2481705e-05)\n",
      "(4, 0.012384275905787945, 3, 0.0011275609)\n",
      "(15, 0.0016676924424245954, 19, 7.12797e-05)\n",
      "(1, 0.0003193861339241266, 4, 2.468633e-06)\n",
      "(9, 0.014703132212162018, 5, 6.001664e-05)\n",
      "(23, 0.11215018481016159, 11, 0.001779435)\n",
      "(12, 0.0036033422220498323, 13, 0.00030817167)\n",
      "(5, 0.012339631095528603, 19, 7.1915083e-06)\n",
      "(3, 0.0007636263035237789, 5, 5.6433026e-07)\n",
      "(15, 0.004675326868891716, 3, 9.562635e-05)\n",
      "(1, 0.00018698842904996127, 19, 0.00011432075)\n",
      "(3, 0.006812641397118568, 13, 0.000117801224)\n",
      "(17, 0.0335240513086319, 7, 0.00015460483)\n",
      "(14, 2.104066965102902e-07, 14, 2.104067e-07)\n",
      "(12, 0.0006857426487840712, 18, 9.340354e-05)\n",
      "(18, 0.08292927592992783, 5, 1.1124102e-05)\n",
      "(17, 0.004245650488883257, 6, 0.0004132879)\n",
      "(20, 0.020548930391669273, 19, 0.00018336422)\n",
      "(13, 0.05032968148589134, 24, 7.733125e-06)\n",
      "(10, 0.01554863341152668, 13, 0.00018967704)\n",
      "(10, 0.001493537100031972, 5, 1.3868826e-05)\n",
      "(10, 0.0002979877754114568, 24, 2.476868e-05)\n",
      "(18, 2.3386417524307035e-05, 14, 5.5168557e-06)\n",
      "(13, 0.0024105103220790625, 1, 0.00020834355)\n",
      "(19, 0.0500171072781086, 4, 0.0008580477)\n",
      "(12, 0.03635047376155853, 19, 0.0014365021)\n",
      "(3, 2.992671034007799e-05, 2, 1.8358747e-06)\n",
      "(3, 0.0010311035439372063, 19, 3.01227e-05)\n",
      "(17, 0.0016030652914196253, 13, 0.0002169277)\n",
      "(1, 0.09097080677747726, 11, 0.0014245732)\n",
      "(15, 0.00403570244088769, 19, 7.871553e-06)\n",
      "(14, 4.221011477056891e-05, 9, 1.3426244e-05)\n",
      "(7, 0.14761723577976227, 13, 0.00010152372)\n",
      "(21, 0.021256525069475174, 2, 4.054758e-05)\n",
      "(20, 0.012775500304996967, 5, 0.0015058425)\n",
      "(14, 0.03560991957783699, 24, 2.4783954e-05)\n",
      "(13, 0.0003468007780611515, 4, 7.5228796e-05)\n",
      "(18, 0.013708357699215412, 2, 9.672146e-06)\n",
      "(4, 0.005463138688355684, 19, 0.00015399067)\n",
      "(20, 0.028185516595840454, 19, 0.00014103914)\n",
      "(15, 0.5142399072647095, 2, 0.00014326621)\n",
      "(20, 0.0016267824685201049, 2, 2.7981398e-05)\n",
      "(12, 0.0003472719108685851, 18, 0.00010335614)\n",
      "(4, 0.0209447480738163, 19, 0.00016037172)\n",
      "(20, 0.018966348841786385, 13, 0.0002448224)\n",
      "(8, 0.07046329230070114, 4, 0.0035247449)\n",
      "(13, 6.005568866385147e-05, 13, 6.005569e-05)\n",
      "(21, 0.00177865254227072, 13, 6.472319e-05)\n",
      "(15, 0.02784622274339199, 13, 6.131559e-05)\n",
      "(3, 0.09013804793357849, 13, 5.919744e-05)\n",
      "(2, 2.7907615276490105e-06, 24, 1.106407e-06)\n",
      "(9, 0.02251012623310089, 19, 0.0010598737)\n",
      "(0, 0.009211702272295952, 18, 0.00014208393)\n",
      "(18, 0.16908884048461914, 10, 0.0021331739)\n",
      "(24, 0.005713014397770166, 13, 4.213117e-06)\n",
      "(4, 0.03275473043322563, 5, 0.0010266241)\n",
      "(12, 0.053652651607990265, 2, 0.0005150022)\n",
      "(9, 0.00011601657752180472, 5, 3.0319927e-06)\n",
      "(3, 0.003117865417152643, 5, 4.884497e-05)\n",
      "(10, 0.012291734106838703, 19, 1.4674222e-05)\n",
      "(17, 6.225120614544721e-06, 13, 5.1115427e-07)\n",
      "(24, 4.2466301238164306e-05, 2, 4.2265492e-05)\n",
      "(9, 2.8397160349413753e-05, 13, 1.3769264e-05)\n",
      "(24, 0.011619075201451778, 5, 0.0032452138)\n",
      "(24, 0.0006795472581870854, 19, 1.5240707e-05)\n",
      "(7, 0.2578144669532776, 13, 2.6775659e-05)\n",
      "(17, 0.003904166864231229, 19, 0.00017252567)\n",
      "(8, 8.511495980201289e-05, 2, 2.3105278e-05)\n",
      "(4, 0.006034041289240122, 5, 4.598115e-05)\n",
      "(8, 2.077767567243427e-05, 3, 1.2828203e-05)\n",
      "(8, 0.004449373111128807, 5, 9.442742e-05)\n",
      "(16, 0.010068870149552822, 2, 7.629405e-05)\n",
      "(17, 0.03549767658114433, 2, 9.461178e-05)\n",
      "(19, 0.0034058887977153063, 24, 9.850412e-06)\n",
      "(2, 0.0025347364135086536, 13, 0.00026817317)\n",
      "(15, 0.0025064623914659023, 19, 0.00035039854)\n",
      "(23, 0.0006502462201751769, 13, 0.00014937988)\n",
      "(10, 0.03152705729007721, 13, 2.469574e-07)\n",
      "(21, 0.012514227069914341, 19, 0.0001697347)\n",
      "(17, 0.007616083137691021, 15, 0.00053748314)\n",
      "(23, 0.012663140892982483, 5, 8.3722975e-05)\n",
      "(7, 0.011864487081766129, 5, 0.00036640847)\n",
      "(23, 0.00916475523263216, 24, 1.3450923e-06)\n",
      "(15, 0.004117419943213463, 13, 0.00035559904)\n",
      "(5, 0.004019354470074177, 3, 9.019891e-05)\n",
      "(23, 0.06123035028576851, 19, 0.0006827958)\n",
      "(13, 0.010390321724116802, 2, 0.0023948574)\n",
      "(3, 0.0031647805590182543, 24, 0.00026075164)\n",
      "(8, 0.026755044236779213, 19, 0.0023105398)\n",
      "(9, 0.09114784002304077, 2, 0.00087955745)\n",
      "(4, 0.04346923530101776, 13, 0.0005512131)\n",
      "(24, 0.04306799918413162, 2, 0.00025677562)\n",
      "(19, 0.005352038890123367, 8, 0.0005064631)\n",
      "(0, 0.00025464704958721995, 2, 4.131992e-05)\n",
      "(7, 0.02314581535756588, 14, 2.9964365e-06)\n",
      "(22, 0.003863052697852254, 2, 2.234271e-05)\n",
      "(1, 0.004011837765574455, 4, 0.00016689047)\n",
      "(2, 2.593858198451926e-06, 2, 2.5938582e-06)\n",
      "(2, 5.031567525293212e-06, 2, 5.0315675e-06)\n",
      "(19, 1.4237517461879179e-05, 19, 1.42375175e-05)\n",
      "(1, 0.02343844808638096, 13, 0.00012994488)\n",
      "(13, 0.003341034520417452, 11, 0.00022383781)\n",
      "(10, 0.0036065815947949886, 5, 3.1563963e-05)\n",
      "(23, 0.12278757989406586, 19, 1.2256972e-05)\n",
      "(16, 0.041413355618715286, 24, 3.7515507e-05)\n",
      "(9, 0.014750995673239231, 12, 0.00033353854)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(y_true_indices, vectors_real, y_pred_indice_mins, y_pred_mins):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
